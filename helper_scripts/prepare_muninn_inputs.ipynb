{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27948b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_PATH = '/home/yutianc/muninn_sc2/inputs/escape_1000/mutations.tsv'\n",
    "\n",
    "IN_DIR = '/home/yutianc/bjorn_rep/data/sc2'\n",
    "OUT_DIR = '/home/yutianc/muninn_sc2/inputs/escape_1000'\n",
    "\n",
    "FASTA_DIR = '/home/yutianc/bjorn_rep/data/sc2/consensus_sequences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af577fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mut = pd.read_csv(MUT_PATH, sep='\\t')\n",
    "dms = pd.read_csv(os.path.join(IN_DIR, \"final_variant_scores_BA.1_BA.2.txt\"), sep=',', header=0)\n",
    "metadata = pd.read_csv(os.path.join(IN_DIR, \"metadata.csv\"))\n",
    "lineage = pd.read_csv(os.path.join(IN_DIR, \"lineage_report.csv\"))\n",
    "evescape = pd.read_csv(os.path.join(IN_DIR, \"full_spike_evescape.csv\"))\n",
    "\n",
    "# the unique samples in the subset, will be used to subset other files\n",
    "sra = list(mut[\"sra\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e3cb1c",
   "metadata": {},
   "source": [
    "## DMS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Hu-1_v1 and Hu-1_v2 are the same thing..\n",
    "dms_v1 = dms[dms['target'] == 'Wuhan-Hu-1_v1']\n",
    "dms_v2 = dms[dms['target'] == 'Wuhan-Hu-1_v2']\n",
    "\n",
    "m = pd.merge(dms_v1, dms_v2, how=\"outer\", on=[\"position\"], indicator=True)\n",
    "assert len(m[m[\"wildtype_x\"] != m['wildtype_y']]) == 0\n",
    "assert len(m[m[\"_merge\"] != 'both']) == 0\n",
    "\n",
    "# they are the same thing, so I will treat both of them as Hu-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f500eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dms = pd.read_csv(os.path.join(IN_DIR, \"final_variant_scores_BA.1_BA.2.txt\"), sep=',', header=0)\n",
    "\n",
    "ref_map = {'Omicron_BA1': 'NC_045512.2_escape_BA.1_rbd',\n",
    "           'Omicron_BA2': 'NC_045512.2_escape_BA.2_rbd',\n",
    "           'Wuhan-Hu-1_v1': 'NC_045512.2',\n",
    "           'Wuhan-Hu-1_v2': 'NC_045512.2',\n",
    "           'Beta': 'Beta',\n",
    "           'Alpha': 'Alpha',\n",
    "           'Delta': 'Delta',\n",
    "           }\n",
    "\n",
    "# this is rbd region only, so YP.. is used here\n",
    "dms['GFF_FEATURE'] = 'YP_009724390.1_' + dms['target'].map(ref_map)\n",
    "\n",
    "# check if gffs are correct\n",
    "mut['mutation'] = mut['ref_aa'] + str(mut['pos_aa']) + mut['alt_aa']\n",
    "merged = pd.merge(dms, mut, how='inner', on=['mutation'], indicator=True)\n",
    "\n",
    "assert not (\n",
    "    (merged[\"_merge\"] == \"both\") &\n",
    "    (merged[\"GFF_FEATURE_x\"] != merged[\"GFF_FEATURE_y\"])\n",
    ").any()\n",
    "\n",
    "\n",
    "# currently only for these ref genomes\n",
    "dms = dms[dms['target'].isin(['Omicron_BA1', 'Omicron_BA2', 'Wuhan-Hu-1_v1', 'Wuhan-Hu-1_v2'])]\n",
    "\n",
    "dms.to_csv(os.path.join(OUT_DIR, \"dms.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23e523",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ada8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"mut_sra\"] = metadata['fasta_hdr'].apply(lambda x: str(x).split(\"/\")[2] if len(str(x).split(\"/\")) == 4 else x)\n",
    "\n",
    "# for those id and fasta_hdr mismatch, overwrite fasta_hdr with id\n",
    "mask = metadata[\"mut_sra\"].notna() & (metadata[\"mut_sra\"] != metadata[\"ID\"])\n",
    "metadata.loc[mask, \"ID\"] = metadata.loc[mask, \"mut_sra\"]\n",
    "\n",
    "metadata_sampled = metadata[metadata[\"mut_sra\"].isin(sra)]\n",
    "metadata_sampled = metadata_sampled.drop(columns={\"mut_sra\"})\n",
    "metadata = metadata.drop(columns={\"mut_sra\"})\n",
    "\n",
    "metadata_sampled.to_csv(os.path.join(OUT_DIR, \"metadata_sampled.tsv\"), sep=\"\\t\", index=False)\n",
    "metadata.to_csv(os.path.join(IN_DIR, \"metadata_cleaned.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c224b4aa",
   "metadata": {},
   "source": [
    "## Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ae7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_first_seq_id(path: Path):\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\">\"):\n",
    "                seq_id = line[1:].split()[0]\n",
    "                seq_id = seq_id.split(\"/\")[2] if len(seq_id.split(\"/\")) ==  4 else seq_id\n",
    "                return seq_id\n",
    "            return None\n",
    "    return None \n",
    "\n",
    "def find_fname_sid_mapping(dir_path: str, exts=(\".fasta\")):\n",
    "    d = Path(dir_path)\n",
    "    fname, sid = [], []\n",
    "\n",
    "    for p in d.iterdir():  # no subdirs\n",
    "        if exts and p.suffix.lower() not in exts:\n",
    "            continue\n",
    "\n",
    "        seq_id = fasta_first_seq_id(p)\n",
    "\n",
    "        fname.append(p.stem)\n",
    "        sid.append(seq_id)\n",
    "\n",
    "    return fname, sid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d503627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarily, overwrite the mismatched taxon with id from fasta file\n",
    "fname, sid = find_fname_sid_mapping(FASTA_DIR)\n",
    "dic_lineage = dict(zip(fname, sid))\n",
    "lineage[\"taxon\"] = lineage[\"taxon\"].map(dic_lineage)\n",
    "\n",
    "lineage_sampled = lineage[lineage[\"taxon\"].isin(sra)]\n",
    "\n",
    "lineage_sampled.to_csv(os.path.join(OUT_DIR, \"lineage_sampled.csv\"), index=False)\n",
    "lineage.to_csv(os.path.join(IN_DIR, \"lineage_cleaned.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b14a6a",
   "metadata": {},
   "source": [
    "## EVEscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b9e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evescape is Hu-1 only\n",
    "# and this file is for spike only, so the corresponding gff is YP_009724390.1\n",
    "\n",
    "evescape[\"GFF_FEATURE\"] = 'YP_009724390.1_NC_045512.2'\n",
    "evescape[\"mutation\"] = evescape[\"wt\"] + evescape[\"i\"] + evescape[\"mut\"]\n",
    "# check if GFFs match with the ones in mut file\n",
    "merged = pd.merge(mut, evescape, on=\"mutation\", how=\"inner\")\n",
    "\n",
    "assert (merged[\"GFF_FEATURE_x\"] == merged[\"GFF_FEATURE_y\"]).all()\n",
    "\n",
    "evescape = evescape.drop(columns={\"mutation\"})\n",
    "evescape.to_csv(os.path.join(OUT_DIR, \"evescape.tsv\"), sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
